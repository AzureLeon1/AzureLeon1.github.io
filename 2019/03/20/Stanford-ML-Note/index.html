<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/icon-180.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/icon-32.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/icon-16.png?v=5.1.4">


  <link rel="mask-icon" href="/images/icon.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="机器学习,吴恩达,">










<meta name="description" content="讲师：Andrew Ng     Date Content     2019-3-16 [L1 : L4]   2019-3-20 [L6 : L12]   2019-4-7 [L14 : L27]   2019-6-6 [L28 : L35]    第1章 绪论：初识机器学习L2 什么是机器学习任务T 经验E 性能度量P L3 监督学习Supervised Learning: “right a">
<meta name="keywords" content="机器学习,吴恩达">
<meta property="og:type" content="article">
<meta property="og:title" content="Stanford ML Note">
<meta property="og:url" content="http://www.leonwang.top/2019/03/20/Stanford-ML-Note/index.html">
<meta property="og:site_name" content="Leon&#39;s Blog">
<meta property="og:description" content="讲师：Andrew Ng     Date Content     2019-3-16 [L1 : L4]   2019-3-20 [L6 : L12]   2019-4-7 [L14 : L27]   2019-6-6 [L28 : L35]    第1章 绪论：初识机器学习L2 什么是机器学习任务T 经验E 性能度量P L3 监督学习Supervised Learning: “right a">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://ww3.sinaimg.cn/large/006tNc79gy1g3qqrpezn7j31uh0u0435.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/006tNc79gy1g3qqroe3hqj314b0u0dhr.jpg">
<meta property="og:image" content="http://ww4.sinaimg.cn/large/006tNc79gy1g3qqrrmd8ij30rk0cwgmc.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/006tNc79gy1g3qqrnw2z8j30mu0fo74t.jpg">
<meta property="og:image" content="http://ww4.sinaimg.cn/large/006tNc79gy1g3qqrnencvj30tu0jctan.jpg">
<meta property="og:image" content="https://ws4.sinaimg.cn/large/006tKfTcgy1g1955i32adj30ry088dg8.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006tKfTcgy1g1955zzel9j30n607qt8x.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/006tNc79gy1g3qqrq77k7j30sw0823zb.jpg">
<meta property="og:image" content="http://ww3.sinaimg.cn/large/006tNc79gy1g3qqrl982oj30qc0fcdgu.jpg">
<meta property="og:image" content="http://ww2.sinaimg.cn/large/006tNc79gy1g3qqrm17t9j30wa0hs0uy.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/006tNc79gy1g3qqrprtmoj30sg0eawfq.jpg">
<meta property="og:image" content="http://ww2.sinaimg.cn/large/006tNc79gy1g3qqrotca2j30j803uweu.jpg">
<meta property="og:image" content="http://ww2.sinaimg.cn/large/006tNc79gy1g3qqrs2m1dj30p40cq3zy.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/006tNc79gy1g3qqrlk5q0j30nk0bm3zt.jpg">
<meta property="og:image" content="http://ww2.sinaimg.cn/large/006tNc79gy1g3qqrra7iuj30oy0dmwgc.jpg">
<meta property="og:image" content="http://ww2.sinaimg.cn/large/006tNc79gy1g3qrsw1ua5j30r80gmwmy.jpg">
<meta property="og:image" content="http://ww4.sinaimg.cn/large/006tNc79gy1g3qrwrnknwj30pc096djq.jpg">
<meta property="og:image" content="http://ww4.sinaimg.cn/large/006tNc79gy1g3qqrqoumcj30j20d8t9j.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/006tNc79gy1g3qqrsljhbj30cq09cwer.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/006tNc79gy1g3qqrmxufuj30m205iq36.jpg">
<meta property="og:image" content="http://ww2.sinaimg.cn/large/006tNc79gy1g3qscfcrogj30di03ct91.jpg">
<meta property="og:image" content="http://ww3.sinaimg.cn/large/006tNc79gy1g3qsgnk2ruj30ue0g4tgs.jpg">
<meta property="og:updated_time" content="2019-06-05T17:30:25.812Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Stanford ML Note">
<meta name="twitter:description" content="讲师：Andrew Ng     Date Content     2019-3-16 [L1 : L4]   2019-3-20 [L6 : L12]   2019-4-7 [L14 : L27]   2019-6-6 [L28 : L35]    第1章 绪论：初识机器学习L2 什么是机器学习任务T 经验E 性能度量P L3 监督学习Supervised Learning: “right a">
<meta name="twitter:image" content="http://ww3.sinaimg.cn/large/006tNc79gy1g3qqrpezn7j31uh0u0435.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://www.leonwang.top/2019/03/20/Stanford-ML-Note/">





  <title>Stanford ML Note | Leon's Blog</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?2e891af0fec421b141ef1add26813124";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Leon's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">不曾经历过真正的沧桑，却失守了最后一点少年意气。</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-github">
          <a href="https://github.com/AzureLeon1" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-github"></i> <br>
            
            Github
          </a>
        </li>
      
        
        <li class="menu-item menu-item-e-mail">
          <a href="mailto:leonwangchn@163.com" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-envelope"></i> <br>
            
            E-Mail
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.leonwang.top/2019/03/20/Stanford-ML-Note/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leon Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leon's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Stanford ML Note</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-20T12:52:02+08:00">
                2019-03-20
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <blockquote>
<p>讲师：Andrew Ng</p>
</blockquote>
<table>
<thead>
<tr>
<th>Date</th>
<th>Content</th>
</tr>
</thead>
<tbody>
<tr>
<td>2019-3-16</td>
<td>[L1 : L4]</td>
</tr>
<tr>
<td>2019-3-20</td>
<td>[L6 : L12]</td>
</tr>
<tr>
<td>2019-4-7</td>
<td>[L14 : L27]</td>
</tr>
<tr>
<td>2019-6-6</td>
<td>[L28 : L35]</td>
</tr>
</tbody>
</table>
<h1 id="第1章-绪论：初识机器学习"><a href="#第1章-绪论：初识机器学习" class="headerlink" title="第1章 绪论：初识机器学习"></a>第1章 绪论：初识机器学习</h1><h2 id="L2-什么是机器学习"><a href="#L2-什么是机器学习" class="headerlink" title="L2 什么是机器学习"></a>L2 什么是机器学习</h2><p>任务T 经验E 性能度量P</p>
<h2 id="L3-监督学习"><a href="#L3-监督学习" class="headerlink" title="L3 监督学习"></a>L3 监督学习</h2><p>Supervised Learning: “right answers” given</p>
<ul>
<li><p>回归(regression)：预测值是连续的</p>
</li>
<li><p>分类(classification)：预测值是离散的</p>
<ul>
<li><p>一个特征：</p>
<p>  可以把样本点投射到特征轴上</p>
<p>  <img src="http://ww3.sinaimg.cn/large/006tNc79gy1g3qqrpezn7j31uh0u0435.jpg" alt="image-20190318112203853"></p>
</li>
<li><p>两个特征：</p>
<p>  用线将样本点分割成不同的区域</p>
<p>  <img src="http://ww1.sinaimg.cn/large/006tNc79gy1g3qqroe3hqj314b0u0dhr.jpg" alt="image-20190318112340525"></p>
</li>
<li><p>更多特征：</p>
<p>  ……    </p>
</li>
</ul>
</li>
</ul>
<h2 id="L4-无监督学习"><a href="#L4-无监督学习" class="headerlink" title="L4 无监督学习"></a>L4 无监督学习</h2><p>Unsupervised Learning</p>
<p>聚类算法(clustering algorithms)</p>
<p>例子：给新闻自动划分主题、根据基因表达程度把人划分为不同群体、判断哪些计算机协同工作而提高数据中心的效率、社交软件分析自动划分社交圈子、根据客户数据划分客户圈、天文分析星系形成理论、处理分析音频</p>
<h1 id="第2章-单变量线性回归"><a href="#第2章-单变量线性回归" class="headerlink" title="第2章 单变量线性回归"></a>第2章 单变量线性回归</h1><h2 id="L6-模型描述"><a href="#L6-模型描述" class="headerlink" title="L6 模型描述"></a>L6 模型描述</h2><p>(x^(i), y^(i))表示第i个训练样本</p>
<p>训练出的模型是一个函数，称为hypothesis函数</p>
<p>简单的例子：单变量线性回归</p>
<p><img src="http://ww4.sinaimg.cn/large/006tNc79gy1g3qqrrmd8ij30rk0cwgmc.jpg" alt="image-20190320100744379"></p>
<h2 id="L7-代价函数"><a href="#L7-代价函数" class="headerlink" title="L7 代价函数"></a>L7 代价函数</h2><p>“#”是训练样本个数的缩写</p>
<p>回归问题常用的代价函数：平方误差代价函数</p>
<p><img src="http://ww1.sinaimg.cn/large/006tNc79gy1g3qqrnw2z8j30mu0fo74t.jpg" alt="image-20190320102031214"></p>
<h2 id="L8-代价函数（一）"><a href="#L8-代价函数（一）" class="headerlink" title="L8 代价函数（一）"></a>L8 代价函数（一）</h2><p>简化上节课的hypothesis（使其只有一个一次项系数参数），然后借助图像，理解hypothesis与代价函数的关系：</p>
<p><img src="http://ww4.sinaimg.cn/large/006tNc79gy1g3qqrnencvj30tu0jctan.jpg" alt="image-20190320103102397"></p>
<h2 id="L9-代价函数（二）"><a href="#L9-代价函数（二）" class="headerlink" title="L9 代价函数（二）"></a>L9 代价函数（二）</h2><p>取消上节课中的简化操作，讨论两个参数的hypothesis。其代价函数图像不再是二维的曲线，而是一个三维的曲面，但可以用二维的等高线图来表示。</p>
<h2 id="L10-梯度下降"><a href="#L10-梯度下降" class="headerlink" title="L10 梯度下降"></a>L10 梯度下降</h2><p>梯度下降算法：求最小化代价函数，不只可以用在线性回归问题</p>
<p>得到的是局部最优</p>
<p>过程：</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1g1955i32adj30ry088dg8.jpg" alt="image-20190320122115449"></p>
<p>定义：</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1g1955zzel9j30n607qt8x.jpg" alt="image-20190320122141341"></p>
<p>:= 赋值</p>
<p>alpha 学习率（梯度下降时迈出多大的步子）</p>
<p>theta0 和 theta1 是<strong>同时更新</strong>的</p>
<p><img src="http://ww1.sinaimg.cn/large/006tNc79gy1g3qqrq77k7j30sw0823zb.jpg" alt="image-20190320121816549"></p>
<p>右边的方法是错误的，因为在计算 theta1 的过程中使用了新的 theta0</p>
<h2 id="L11-梯度下降知识点总结"><a href="#L11-梯度下降知识点总结" class="headerlink" title="L11 梯度下降知识点总结"></a>L11 梯度下降知识点总结</h2><p>以单变量函数的梯度下降法为例，理解梯度下降法中导数部分和学习率alpha的意义。</p>
<h2 id="L12-线性回归的梯度下降"><a href="#L12-线性回归的梯度下降" class="headerlink" title="L12 线性回归的梯度下降"></a>L12 线性回归的梯度下降</h2><p>平方代价函数 + 梯度下降法</p>
<p>Batch梯度下降算法：每一步梯度下降都遍历了<strong>整个</strong>训练集的样本。</p>
<h1 id="第3章-线性代数回顾"><a href="#第3章-线性代数回顾" class="headerlink" title="第3章 线性代数回顾"></a>第3章 线性代数回顾</h1><h2 id="L14-矩阵和向量"><a href="#L14-矩阵和向量" class="headerlink" title="L14 矩阵和向量"></a>L14 矩阵和向量</h2><p>维数：</p>
<p>​    矩阵 m行n列 （二维）</p>
<p>​    向量 n行1列 （一维）</p>
<p>没有特殊说明的情况下，默认向量的下标从1开始，而不是从0。</p>
<h2 id="L15-加法和标量乘法"><a href="#L15-加法和标量乘法" class="headerlink" title="L15 加法和标量乘法"></a>L15 加法和标量乘法</h2><h2 id="L16-矩阵向量乘法"><a href="#L16-矩阵向量乘法" class="headerlink" title="L16 矩阵向量乘法"></a>L16 矩阵向量乘法</h2><p>形式：</p>
<p><img src="http://ww3.sinaimg.cn/large/006tNc79gy1g3qqrl982oj30qc0fcdgu.jpg" alt="image-20190407025119044"></p>
<p>实际应用：</p>
<p><img src="http://ww2.sinaimg.cn/large/006tNc79gy1g3qqrm17t9j30wa0hs0uy.jpg" alt="image-20190407025043184"></p>
<p>代码用矩阵向量乘法表示而不是用for循环的优点：</p>
<ol>
<li>代码简洁</li>
<li>计算效率更高</li>
</ol>
<h2 id="L17-矩阵乘法"><a href="#L17-矩阵乘法" class="headerlink" title="L17 矩阵乘法"></a>L17 矩阵乘法</h2><p>用于多个hypotheses函数的情形：</p>
<p><img src="http://ww1.sinaimg.cn/large/006tNc79gy1g3qqrprtmoj30sg0eawfq.jpg" alt="image-20190407025343393"></p>
<p>应用：高效地进行多个假设的计算</p>
<h2 id="L18-矩阵乘法特征"><a href="#L18-矩阵乘法特征" class="headerlink" title="L18 矩阵乘法特征"></a>L18 矩阵乘法特征</h2><p>矩阵乘法</p>
<ul>
<li>不服从交换律</li>
<li>服从结合律</li>
<li>单位矩阵的概念</li>
</ul>
<h2 id="L19-逆和转置"><a href="#L19-逆和转置" class="headerlink" title="L19 逆和转置"></a>L19 逆和转置</h2><p><img src="http://ww2.sinaimg.cn/large/006tNc79gy1g3qqrotca2j30j803uweu.jpg" alt="image-20190407030103743"></p>
<p>奇异矩阵/退化矩阵：没有逆矩阵的矩阵，比如全零矩阵</p>
<h1 id="第5章-多变量线性回归"><a href="#第5章-多变量线性回归" class="headerlink" title="第5章 多变量线性回归"></a>第5章 多变量线性回归</h1><h2 id="L28-多功能"><a href="#L28-多功能" class="headerlink" title="L28 多功能"></a>L28 多功能</h2><p>例：多变量预测房屋价格</p>
<p><img src="http://ww2.sinaimg.cn/large/006tNc79gy1g3qqrs2m1dj30p40cq3zy.jpg" alt="image-20190605222046190"></p>
<p>假设形式：</p>
<p><img src="http://ww1.sinaimg.cn/large/006tNc79gy1g3qqrlk5q0j30nk0bm3zt.jpg" alt="image-20190605222306389"></p>
<p>（惯例：x_0 = 1）</p>
<h2 id="L29-多元梯度下降法"><a href="#L29-多元梯度下降法" class="headerlink" title="L29 多元梯度下降法"></a>L29 多元梯度下降法</h2><p>多元梯度下降法的更新规则：单变量vs多变量</p>
<p><img src="http://ww2.sinaimg.cn/large/006tNc79gy1g3qqrra7iuj30oy0dmwgc.jpg" alt="image-20190605222750730"></p>
<h2 id="L30-多元梯度下降法演练1——特征缩放"><a href="#L30-多元梯度下降法演练1——特征缩放" class="headerlink" title="L30 多元梯度下降法演练1——特征缩放"></a>L30 多元梯度下降法演练1——特征缩放</h2><p><strong>特征缩放：</strong></p>
<p><img src="http://ww2.sinaimg.cn/large/006tNc79gy1g3qrsw1ua5j30r80gmwmy.jpg" alt="image-20190606010011784"></p>
<p>如果不同特征的取值范围相差较大，则代价函数图像可能不理想（例如上图太细长），导致梯度下降时不断振荡才能收敛到全局最优。</p>
<p>通过特征缩放，可以让梯度下降找到一条更直接的路径。</p>
<p>不要求特征的范围完全相同，但应该接近。</p>
<p><strong>均值归一化：</strong></p>
<p><img src="http://ww4.sinaimg.cn/large/006tNc79gy1g3qrwrnknwj30pc096djq.jpg" alt="image-20190606010355412"></p>
<p>通过减去一个常数，使特征的均值在0附近。</p>
<p>通常的做法： x减去均值，再除以范围的长度。</p>
<p>目的：特征缩放不需要太精确，只是为了让梯度下降更快速。</p>
<h2 id="L31-多元梯度下降法2——学习率"><a href="#L31-多元梯度下降法2——学习率" class="headerlink" title="L31 多元梯度下降法2——学习率"></a>L31 多元梯度下降法2——学习率</h2><p>通过观察”代价函数-迭代步数”图来判断和调整学习率</p>
<p>理想学习率的情况下：</p>
<p><img src="http://ww4.sinaimg.cn/large/006tNc79gy1g3qqrqoumcj30j20d8t9j.jpg" alt="image-20190605224016607"></p>
<p>学习率过大的情况：</p>
<p><img src="http://ww1.sinaimg.cn/large/006tNc79gy1g3qqrsljhbj30cq09cwer.jpg" alt="image-20190605224046417"></p>
<p>对于上面的两种情况，通常调小学习率可以解决。</p>
<p>但是学习率不能太小，否则收敛很慢。</p>
<p>选择学习率的策略：</p>
<p><img src="http://ww1.sinaimg.cn/large/006tNc79gy1g3qqrmxufuj30m205iq36.jpg" alt="image-20190605224259590"></p>
<p>每隔3倍取一个，找到过大的和过小的学习率。通常去尝试比 过大的学习率 稍小一点的数作为学习率。</p>
<h2 id="L32-特征和多项式回归"><a href="#L32-特征和多项式回归" class="headerlink" title="L32 特征和多项式回归"></a>L32 特征和多项式回归</h2><p>不只用直线进行拟合，可以用多项式函数。</p>
<p>假设函数是多项式时，特征缩放尤其重要。</p>
<h2 id="L33-正规方程（区别于迭代方法的直接解法）"><a href="#L33-正规方程（区别于迭代方法的直接解法）" class="headerlink" title="L33 正规方程（区别于迭代方法的直接解法）"></a>L33 正规方程（区别于迭代方法的直接解法）</h2><p><img src="http://ww2.sinaimg.cn/large/006tNc79gy1g3qscfcrogj30di03ct91.jpg" alt="image-20190606011858017"></p>
<p>特征方程法给出了直接求解令代价函数最小化的参数向量的计算方法。</p>
<p>正规方程法不需要做特征缩放。</p>
<p><strong>梯度下降法和正规方程法的比较：</strong></p>
<p><img src="http://ww3.sinaimg.cn/large/006tNc79gy1g3qsgnk2ruj30ue0g4tgs.jpg" alt="image-20190606012301141"></p>
<p>当n的规模较大时，梯度下降法的表现比正规方程法好。</p>
<h2 id="L34-正规方程在矩阵X‘X不可逆情况下的解决方法"><a href="#L34-正规方程在矩阵X‘X不可逆情况下的解决方法" class="headerlink" title="L34 正规方程在矩阵X‘X不可逆情况下的解决方法"></a>L34 正规方程在矩阵X‘X不可逆情况下的解决方法</h2><p>没有逆的矩阵：奇异或退化矩阵</p>
<p>可以使用编程包中计算 <strong>伪逆</strong> 的方法来计算。</p>
<p>机器学习中矩阵X’X不可逆的<strong>原因</strong>通常考虑：</p>
<ul>
<li>包含了多余的特征（比如米和英尺存在定值转换的关系）</li>
<li>特征太多（比如样本数小于特征数） -&gt; 尝试 删掉部分特征 或 正则化</li>
</ul>
<h1 id="第7章-Logistic回归"><a href="#第7章-Logistic回归" class="headerlink" title="第7章 Logistic回归"></a>第7章 Logistic回归</h1><h2 id="L46-分类"><a href="#L46-分类" class="headerlink" title="L46 分类"></a>L46 分类</h2><h2 id="L47-假设陈述"><a href="#L47-假设陈述" class="headerlink" title="L47 假设陈述"></a>L47 假设陈述</h2><h2 id="L48-决策界限"><a href="#L48-决策界限" class="headerlink" title="L48 决策界限"></a>L48 决策界限</h2><h2 id="L49-代价函数"><a href="#L49-代价函数" class="headerlink" title="L49 代价函数"></a>L49 代价函数</h2><h2 id="L50-简化代价函数与梯度下降"><a href="#L50-简化代价函数与梯度下降" class="headerlink" title="L50 简化代价函数与梯度下降"></a>L50 简化代价函数与梯度下降</h2><h2 id="L51-高级优化"><a href="#L51-高级优化" class="headerlink" title="L51 高级优化"></a>L51 高级优化</h2><h2 id="L52-多元分类：一对多"><a href="#L52-多元分类：一对多" class="headerlink" title="L52 多元分类：一对多"></a>L52 多元分类：一对多</h2><h1 id="第8章-正则化"><a href="#第8章-正则化" class="headerlink" title="第8章 正则化"></a>第8章 正则化</h1><h2 id="L55-过拟合问题"><a href="#L55-过拟合问题" class="headerlink" title="L55 过拟合问题"></a>L55 过拟合问题</h2><h2 id="L56-代价函数"><a href="#L56-代价函数" class="headerlink" title="L56 代价函数"></a>L56 代价函数</h2><h2 id="L57-线性回归的正则化"><a href="#L57-线性回归的正则化" class="headerlink" title="L57 线性回归的正则化"></a>L57 线性回归的正则化</h2><h2 id="L61-Logistic回归的正则化"><a href="#L61-Logistic回归的正则化" class="headerlink" title="L61 Logistic回归的正则化"></a>L61 Logistic回归的正则化</h2><h1 id="第9章-神经网络学习"><a href="#第9章-神经网络学习" class="headerlink" title="第9章 神经网络学习"></a>第9章 神经网络学习</h1><h2 id="L62-非线性假设"><a href="#L62-非线性假设" class="headerlink" title="L62 非线性假设"></a>L62 非线性假设</h2><h2 id="L63-神经元与大脑"><a href="#L63-神经元与大脑" class="headerlink" title="L63 神经元与大脑"></a>L63 神经元与大脑</h2><h2 id="L64-模型展示1"><a href="#L64-模型展示1" class="headerlink" title="L64 模型展示1"></a>L64 模型展示1</h2><h2 id="L65-模型展示2"><a href="#L65-模型展示2" class="headerlink" title="L65 模型展示2"></a>L65 模型展示2</h2><h2 id="L68-例子与直觉理解1"><a href="#L68-例子与直觉理解1" class="headerlink" title="L68 例子与直觉理解1"></a>L68 例子与直觉理解1</h2><h2 id="L70-例子与直觉理解2"><a href="#L70-例子与直觉理解2" class="headerlink" title="L70 例子与直觉理解2"></a>L70 例子与直觉理解2</h2><h2 id="L71-多元分类"><a href="#L71-多元分类" class="headerlink" title="L71 多元分类"></a>L71 多元分类</h2><h1 id="第10章-神经网络参数的反向传播算法"><a href="#第10章-神经网络参数的反向传播算法" class="headerlink" title="第10章 神经网络参数的反向传播算法"></a>第10章 神经网络参数的反向传播算法</h1><h2 id="L72-代价函数"><a href="#L72-代价函数" class="headerlink" title="L72 代价函数"></a>L72 代价函数</h2><h2 id="L73-反向传播算法"><a href="#L73-反向传播算法" class="headerlink" title="L73 反向传播算法"></a>L73 反向传播算法</h2><h2 id="L74-理解反向传播"><a href="#L74-理解反向传播" class="headerlink" title="L74 理解反向传播"></a>L74 理解反向传播</h2><h2 id="L75-使用注意：展开参数"><a href="#L75-使用注意：展开参数" class="headerlink" title="L75 使用注意：展开参数"></a>L75 使用注意：展开参数</h2><h2 id="L76-梯度检测"><a href="#L76-梯度检测" class="headerlink" title="L76 梯度检测"></a>L76 梯度检测</h2><h2 id="L77-随机初始化"><a href="#L77-随机初始化" class="headerlink" title="L77 随机初始化"></a>L77 随机初始化</h2><h2 id="L78-组合到一起"><a href="#L78-组合到一起" class="headerlink" title="L78 组合到一起"></a>L78 组合到一起</h2><h2 id="L80-无人驾驶"><a href="#L80-无人驾驶" class="headerlink" title="L80 无人驾驶"></a>L80 无人驾驶</h2>
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
            <a href="/tags/吴恩达/" rel="tag"># 吴恩达</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/03/19/Analysis-and-Design-of-Algorithms/" rel="next" title="Analysis and Design of Algorithms">
                <i class="fa fa-chevron-left"></i> Analysis and Design of Algorithms
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/05/08/Fetch-API-检测请求是否成功/" rel="prev" title="Fetch API 检测请求是否成功">
                Fetch API 检测请求是否成功 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpeg" alt="Leon Wang">
            
              <p class="site-author-name" itemprop="name">Leon Wang</p>
              <p class="site-description motion-element" itemprop="description">不曾经历过真正的沧桑，却失守了最后一点少年意气。</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">18</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">23</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#第1章-绪论：初识机器学习"><span class="nav-number">1.</span> <span class="nav-text">第1章 绪论：初识机器学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#L2-什么是机器学习"><span class="nav-number">1.1.</span> <span class="nav-text">L2 什么是机器学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L3-监督学习"><span class="nav-number">1.2.</span> <span class="nav-text">L3 监督学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L4-无监督学习"><span class="nav-number">1.3.</span> <span class="nav-text">L4 无监督学习</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第2章-单变量线性回归"><span class="nav-number">2.</span> <span class="nav-text">第2章 单变量线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#L6-模型描述"><span class="nav-number">2.1.</span> <span class="nav-text">L6 模型描述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L7-代价函数"><span class="nav-number">2.2.</span> <span class="nav-text">L7 代价函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L8-代价函数（一）"><span class="nav-number">2.3.</span> <span class="nav-text">L8 代价函数（一）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L9-代价函数（二）"><span class="nav-number">2.4.</span> <span class="nav-text">L9 代价函数（二）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L10-梯度下降"><span class="nav-number">2.5.</span> <span class="nav-text">L10 梯度下降</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L11-梯度下降知识点总结"><span class="nav-number">2.6.</span> <span class="nav-text">L11 梯度下降知识点总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L12-线性回归的梯度下降"><span class="nav-number">2.7.</span> <span class="nav-text">L12 线性回归的梯度下降</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第3章-线性代数回顾"><span class="nav-number">3.</span> <span class="nav-text">第3章 线性代数回顾</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#L14-矩阵和向量"><span class="nav-number">3.1.</span> <span class="nav-text">L14 矩阵和向量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L15-加法和标量乘法"><span class="nav-number">3.2.</span> <span class="nav-text">L15 加法和标量乘法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L16-矩阵向量乘法"><span class="nav-number">3.3.</span> <span class="nav-text">L16 矩阵向量乘法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L17-矩阵乘法"><span class="nav-number">3.4.</span> <span class="nav-text">L17 矩阵乘法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L18-矩阵乘法特征"><span class="nav-number">3.5.</span> <span class="nav-text">L18 矩阵乘法特征</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L19-逆和转置"><span class="nav-number">3.6.</span> <span class="nav-text">L19 逆和转置</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第5章-多变量线性回归"><span class="nav-number">4.</span> <span class="nav-text">第5章 多变量线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#L28-多功能"><span class="nav-number">4.1.</span> <span class="nav-text">L28 多功能</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L29-多元梯度下降法"><span class="nav-number">4.2.</span> <span class="nav-text">L29 多元梯度下降法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L30-多元梯度下降法演练1——特征缩放"><span class="nav-number">4.3.</span> <span class="nav-text">L30 多元梯度下降法演练1——特征缩放</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L31-多元梯度下降法2——学习率"><span class="nav-number">4.4.</span> <span class="nav-text">L31 多元梯度下降法2——学习率</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L32-特征和多项式回归"><span class="nav-number">4.5.</span> <span class="nav-text">L32 特征和多项式回归</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L33-正规方程（区别于迭代方法的直接解法）"><span class="nav-number">4.6.</span> <span class="nav-text">L33 正规方程（区别于迭代方法的直接解法）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L34-正规方程在矩阵X‘X不可逆情况下的解决方法"><span class="nav-number">4.7.</span> <span class="nav-text">L34 正规方程在矩阵X‘X不可逆情况下的解决方法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第7章-Logistic回归"><span class="nav-number">5.</span> <span class="nav-text">第7章 Logistic回归</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#L46-分类"><span class="nav-number">5.1.</span> <span class="nav-text">L46 分类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L47-假设陈述"><span class="nav-number">5.2.</span> <span class="nav-text">L47 假设陈述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L48-决策界限"><span class="nav-number">5.3.</span> <span class="nav-text">L48 决策界限</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L49-代价函数"><span class="nav-number">5.4.</span> <span class="nav-text">L49 代价函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L50-简化代价函数与梯度下降"><span class="nav-number">5.5.</span> <span class="nav-text">L50 简化代价函数与梯度下降</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L51-高级优化"><span class="nav-number">5.6.</span> <span class="nav-text">L51 高级优化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L52-多元分类：一对多"><span class="nav-number">5.7.</span> <span class="nav-text">L52 多元分类：一对多</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第8章-正则化"><span class="nav-number">6.</span> <span class="nav-text">第8章 正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#L55-过拟合问题"><span class="nav-number">6.1.</span> <span class="nav-text">L55 过拟合问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L56-代价函数"><span class="nav-number">6.2.</span> <span class="nav-text">L56 代价函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L57-线性回归的正则化"><span class="nav-number">6.3.</span> <span class="nav-text">L57 线性回归的正则化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L61-Logistic回归的正则化"><span class="nav-number">6.4.</span> <span class="nav-text">L61 Logistic回归的正则化</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第9章-神经网络学习"><span class="nav-number">7.</span> <span class="nav-text">第9章 神经网络学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#L62-非线性假设"><span class="nav-number">7.1.</span> <span class="nav-text">L62 非线性假设</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L63-神经元与大脑"><span class="nav-number">7.2.</span> <span class="nav-text">L63 神经元与大脑</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L64-模型展示1"><span class="nav-number">7.3.</span> <span class="nav-text">L64 模型展示1</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L65-模型展示2"><span class="nav-number">7.4.</span> <span class="nav-text">L65 模型展示2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L68-例子与直觉理解1"><span class="nav-number">7.5.</span> <span class="nav-text">L68 例子与直觉理解1</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L70-例子与直觉理解2"><span class="nav-number">7.6.</span> <span class="nav-text">L70 例子与直觉理解2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L71-多元分类"><span class="nav-number">7.7.</span> <span class="nav-text">L71 多元分类</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第10章-神经网络参数的反向传播算法"><span class="nav-number">8.</span> <span class="nav-text">第10章 神经网络参数的反向传播算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#L72-代价函数"><span class="nav-number">8.1.</span> <span class="nav-text">L72 代价函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L73-反向传播算法"><span class="nav-number">8.2.</span> <span class="nav-text">L73 反向传播算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L74-理解反向传播"><span class="nav-number">8.3.</span> <span class="nav-text">L74 理解反向传播</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L75-使用注意：展开参数"><span class="nav-number">8.4.</span> <span class="nav-text">L75 使用注意：展开参数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L76-梯度检测"><span class="nav-number">8.5.</span> <span class="nav-text">L76 梯度检测</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L77-随机初始化"><span class="nav-number">8.6.</span> <span class="nav-text">L77 随机初始化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L78-组合到一起"><span class="nav-number">8.7.</span> <span class="nav-text">L78 组合到一起</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#L80-无人驾驶"><span class="nav-number">8.8.</span> <span class="nav-text">L80 无人驾驶</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>

<span>鲁ICP备 -
  <a href="http://www.miitbeian.gov.cn/">18054179号</a></span>

  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Leon Wang</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  





<script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"left","width":100,"height":200},"mobile":{"show":true},"log":false});</script></body>
</html>
